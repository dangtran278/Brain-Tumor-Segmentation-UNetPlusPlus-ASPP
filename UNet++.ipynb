{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "# UNet++ for Brain Tumor Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchio as tio\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from models.unetplusplus import Generic_UNetPlusPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b25669",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_helper = lambda x: F.softmax(x, 1)\n",
    "\n",
    "class InitWeights_He(object):\n",
    "    def __init__(self, neg_slope=1e-2):\n",
    "        self.neg_slope = neg_slope\n",
    "\n",
    "    def __call__(self, module):\n",
    "        if isinstance(module, nn.Conv3d) or isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.ConvTranspose3d):\n",
    "            module.weight = nn.init.kaiming_normal_(module.weight, a=self.neg_slope)\n",
    "            if module.bias is not None:\n",
    "                module.bias = nn.init.constant_(module.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = torch.load(\"data/brats_train.pt\")\n",
    "X_val, y_val = torch.load(\"data/brats_val.pt\")\n",
    "X_test, y_test = torch.load(\"data/brats_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "## 3. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class BraTSDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.X[idx].float()\n",
    "        mask = self.y[idx].long()\n",
    "\n",
    "        # Clamp mask values just in case\n",
    "        mask = torch.clamp(mask, 0, 3)\n",
    "\n",
    "        if self.transform:\n",
    "            # Create a TorchIO Subject\n",
    "            subject = tio.Subject(\n",
    "                image=tio.ScalarImage(tensor=img.unsqueeze(0)),\n",
    "                mask=tio.LabelMap(tensor=mask.unsqueeze(0))\n",
    "            )\n",
    "            transformed_subject = self.transform(subject)\n",
    "            img = transformed_subject.image.data.squeeze(0)\n",
    "            mask = transformed_subject.mask.data.squeeze(0)\n",
    "\n",
    "        if mask.ndim == 2:\n",
    "             mask = mask.unsqueeze(0)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "transform = tio.Compose([\n",
    "    tio.RescaleIntensity(out_min_max=(0, 1), percentiles=(0.5, 99.5)),\n",
    "])\n",
    "\n",
    "train_dataset = BraTSDataset(X_train, y_train, transform=transform)\n",
    "val_dataset = BraTSDataset(X_val, y_val)\n",
    "test_dataset = BraTSDataset(X_test, y_test)\n",
    "\n",
    "try:\n",
    "    img, mask = train_dataset[0]\n",
    "    print(f'Sample 0 - Image shape: {img.shape}, Mask shape: {mask.shape}')\n",
    "    print(f'Image dtype: {img.dtype}, Mask dtype: {mask.dtype}')\n",
    "    print(f'Image value range: [{img.min()}, {img.max()}]')\n",
    "    print(f'Unique mask values: {torch.unique(mask)}')\n",
    "except IndexError:\n",
    "     print(\"Could not get sample from dataset. Check data loading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def plot_samples(dataset, num_samples=4):\n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4 * num_samples))  # 3 inputs + 1 mask\n",
    "    if num_samples > len(dataset):\n",
    "        print(f\"Warning: Requested {num_samples} samples, but dataset only has {len(dataset)}.\")\n",
    "        num_samples = len(dataset)\n",
    "    if num_samples == 0:\n",
    "        print(\"No samples to plot.\")\n",
    "        return\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        img, mask = dataset[i]\n",
    "        # img: (3, H, W), mask: (1, H, W)\n",
    "        img = img.cpu().numpy()\n",
    "        mask = mask.squeeze().cpu().numpy() # Squeeze channel dim for plotting\n",
    "\n",
    "        # Assuming channel order: FLAIR, T1CE, T2\n",
    "        flair = img[0]\n",
    "        t1ce = img[1]\n",
    "        t2 = img[2]\n",
    "\n",
    "        axes[i, 0].imshow(flair, cmap='gray')\n",
    "        axes[i, 0].set_title(f'Sample {i} - FLAIR')\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        axes[i, 1].imshow(t1ce, cmap='gray')\n",
    "        axes[i, 1].set_title(f'Sample {i} - T1CE')\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "        axes[i, 2].imshow(t2, cmap='gray')\n",
    "        axes[i, 2].set_title(f'Sample {i} - T2')\n",
    "        axes[i, 2].axis('off')\n",
    "\n",
    "        axes[i, 3].imshow(mask, cmap='tab10', vmin=0, vmax=3) # Use tab10 colormap, set vmin/vmax\n",
    "        axes[i, 3].set_title(f'Sample {i} - Segmentation')\n",
    "        axes[i, 3].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot samples from the training dataset\n",
    "plot_samples(train_dataset, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "## 4. Model Definition (Generic UNet++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    ".\n",
    "print(\"Generic_UNetPlusPlus model imported from utils.unetplusplus\")\n",
    "\n",
    "input_channels = 3\n",
    "base_num_features = 32 # Initial number of filters (nnU-Net default is 30 or 32)\n",
    "num_classes = 4\n",
    "num_pool = 5 # Number of pooling layers (corresponds to U-Net depth)\n",
    "pool_op_kernel_sizes = [(2, 2)] * num_pool\n",
    "conv_kernel_sizes = [(3, 3)] * (num_pool + 1)\n",
    "\n",
    "unet_plusplus_model = Generic_UNetPlusPlus(\n",
    "    input_channels=input_channels,\n",
    "    base_num_features=base_num_features,\n",
    "    num_classes=num_classes,\n",
    "    num_pool=num_pool,\n",
    "    num_conv_per_stage=2,\n",
    "    feat_map_mul_on_downscale=2,\n",
    "    conv_op=nn.Conv2d,\n",
    "    norm_op=nn.BatchNorm2d,\n",
    "    norm_op_kwargs={'eps': 1e-5, 'affine': True},\n",
    "    dropout_op=nn.Dropout2d,\n",
    "    dropout_op_kwargs={'p': 0, 'inplace': True}, # No dropout in standard U-Net\n",
    "    nonlin=nn.LeakyReLU,\n",
    "    nonlin_kwargs={'negative_slope': 1e-2, 'inplace': True},\n",
    "    deep_supervision=True, # UNet++ uses deep supervision\n",
    "    dropout_in_localization=False,\n",
    "    final_nonlin=softmax_helper,\n",
    "    weightInitializer=InitWeights_He(1e-2),\n",
    "    pool_op_kernel_sizes=pool_op_kernel_sizes,\n",
    "    conv_kernel_sizes=conv_kernel_sizes,\n",
    "    upscale_logits=False,\n",
    "    convolutional_pooling=True,\n",
    "    convolutional_upsampling=True,\n",
    "    max_num_features=None \n",
    ")\n",
    "\n",
    "print(\"Generic_UNetPlusPlus model instantiated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "## 5. Loss Function and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def dice_coeff_multiclass(pred, target, smooth=1e-6):\n",
    "    \"\"\"Calculates Dice Coefficient for multi-class segmentation.\"\"\"\n",
    "    num_classes = pred.shape[1]\n",
    "    pred_probs = F.softmax(pred, dim=1)\n",
    "    pred_masks = F.one_hot(torch.argmax(pred_probs, dim=1), num_classes).permute(0, 3, 1, 2).float()\n",
    "    target_masks = F.one_hot(target.squeeze(1), num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "    intersection = torch.sum(pred_masks * target_masks, dim=(2, 3))\n",
    "    union = torch.sum(pred_masks, dim=(2, 3)) + torch.sum(target_masks, dim=(2, 3))\n",
    "\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice.mean(dim=1)\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return (1 - dice_coeff_multiclass(pred, target)).mean()\n",
    "\n",
    "class DiceCELoss(nn.Module):\n",
    "    \"\"\"Combines Dice Loss and Cross Entropy Loss.\"\"\"\n",
    "    def __init__(self, dice_weight=0.5, ce_weight=0.5, class_weights=None, ignore_index=-100):\n",
    "        super(DiceCELoss, self).__init__()\n",
    "        self.dice_weight = dice_weight\n",
    "        self.ce_weight = ce_weight\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.ce_loss = nn.CrossEntropyLoss(weight=class_weights, ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        target_long_squeezed = target.squeeze(1).long()\n",
    "        dice = self.dice_loss(pred, target)\n",
    "        ce = self.ce_loss(pred, target_long_squeezed)\n",
    "        return self.dice_weight * dice + self.ce_weight * ce\n",
    "\n",
    "def iou_score_multiclass(pred, target, smooth=1e-6):\n",
    "    \"\"\"Calculates Intersection over Union (IoU) for multi-class segmentation.\"\"\"\n",
    "    num_classes = pred.shape[1]\n",
    "    pred_probs = F.softmax(pred, dim=1)\n",
    "    pred_masks = F.one_hot(torch.argmax(pred_probs, dim=1), num_classes).permute(0, 3, 1, 2).float()\n",
    "    target_masks = F.one_hot(target.squeeze(1), num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "    intersection = torch.sum(pred_masks * target_masks, dim=(2, 3))\n",
    "    union = torch.sum(pred_masks, dim=(2, 3)) + torch.sum(target_masks, dim=(2, 3)) - intersection\n",
    "\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou.mean(dim=1) # Mean IoU per sample in batch\n",
    "\n",
    "def compute_deep_supervision_loss(criterion, outputs, target):\n",
    "    \"\"\"Computes loss for deep supervision outputs from Generic_UNetPlusPlus.\"\"\"\n",
    "    # Generic_UNetPlusPlus returns a tuple of segmentations if deep_supervision=True\n",
    "    # The first element is the final output, the rest are from intermediate layers.\n",
    "    # We weight the losses, giving more weight to the final output.\n",
    "    if isinstance(outputs, tuple):\n",
    "        # Example weights: [0.5, 0.2, 0.1, 0.1, 0.1] for 5 outputs\n",
    "        # Adjust weights based on the number of outputs\n",
    "        num_outputs = len(outputs)\n",
    "        weights = np.array([1 / (2 ** i) for i in range(num_outputs)])\n",
    "        weights = weights / weights.sum() # Normalize\n",
    "\n",
    "        total_loss = 0\n",
    "        for i, output in enumerate(outputs):\n",
    "            # Resize intermediate outputs to match target size if needed\n",
    "            if output.shape[2:] != target.shape[2:]:\n",
    "                output = F.interpolate(output, size=target.shape[2:], mode='bilinear', align_corners=False)\n",
    "            total_loss += weights[i] * criterion(output, target)\n",
    "        return total_loss\n",
    "    else:\n",
    "        # If not deep supervision, just compute the standard loss\n",
    "        return criterion(outputs, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "## 6. Training and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device, dtype, use_deep_supervision=True):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_iou = 0.0\n",
    "    total_dice = 0.0\n",
    "    num_batches = len(loader)\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs = inputs.to(device, dtype=dtype)\n",
    "        labels = labels.to(device) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss (handle deep supervision if enabled)\n",
    "        if use_deep_supervision and isinstance(outputs, tuple):\n",
    "            loss = compute_deep_supervision_loss(criterion, outputs, labels)\n",
    "            final_output = outputs[0]\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "            final_output = outputs\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            iou = iou_score_multiclass(final_output, labels).mean()\n",
    "            dice = dice_coeff_multiclass(final_output, labels).mean()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_iou += iou.item()\n",
    "        total_dice += dice.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_iou = total_iou / num_batches\n",
    "    avg_dice = total_dice / num_batches\n",
    "    return avg_loss, avg_iou, avg_dice\n",
    "\n",
    "def evaluate(model, loader, criterion, device, dtype, use_deep_supervision=True):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_iou = 0.0\n",
    "    total_dice = 0.0\n",
    "    num_batches = len(loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device, dtype=dtype)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss (handle deep supervision if enabled)\n",
    "            if use_deep_supervision and isinstance(outputs, tuple):\n",
    "                loss = compute_deep_supervision_loss(criterion, outputs, labels)\n",
    "                final_output = outputs[0]\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "                final_output = outputs\n",
    "\n",
    "            iou = iou_score_multiclass(final_output, labels).mean()\n",
    "            dice = dice_coeff_multiclass(final_output, labels).mean()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_iou += iou.item()\n",
    "            total_dice += dice.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_iou = total_iou / num_batches\n",
    "    avg_dice = total_dice / num_batches\n",
    "    return avg_loss, avg_iou, avg_dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32\n",
    "save_path = 'checkpoints/unetplusplus_brats_dce_adam.pth'\n",
    "print_every = 1\n",
    "use_deep_supervision = True\n",
    "\n",
    "batch_size = 4\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-4\n",
    "\n",
    "model = unet_plusplus_model\n",
    "model = model.to(device)\n",
    "\n",
    "# Optional: Define class weights (example, adjust based on dataset analysis)\n",
    "class_weights = torch.tensor([1.0, 10.0, 5.0, 8.0]).to(device, dtype=dtype) # Example weights\n",
    "\n",
    "criterion = DiceCELoss(dice_weight=0.5, ce_weight=0.5, class_weights=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Model: Generic UNet++ (Deep Supervision: {use_deep_supervision})\")\n",
    "print(f\"Input channels: {input_channels}, Num classes: {num_classes}\")\n",
    "print(f\"Batch size: {batch_size}, Epochs: {num_epochs}, LR: {learning_rate}\")\n",
    "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# --- Training Loop ---\n",
    "best_val_iou = -1.0\n",
    "train_losses, val_losses = [], []\n",
    "train_ious, val_ious = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_iou, train_dice = train_epoch(model, train_loader, optimizer, criterion, device, dtype, use_deep_supervision)\n",
    "    val_loss, val_iou, val_dice = evaluate(model, val_loader, criterion, device, dtype, use_deep_supervision)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_ious.append(train_iou)\n",
    "    val_ious.append(val_iou)\n",
    "\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}, Train Dice: {train_dice:.4f}')\n",
    "        print(f'          | Val Loss:   {val_loss:.4f}, Val IoU:   {val_iou:.4f}, Val Dice:   {val_dice:.4f}')\n",
    "\n",
    "    # Save model if validation IoU improves\n",
    "    if val_iou > best_val_iou:\n",
    "        best_val_iou = val_iou\n",
    "        # Ensure checkpoints directory exists\n",
    "        import os\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f'          | Model saved to {save_path} (Val IoU improved to {best_val_iou:.4f})')\n",
    "\n",
    "print(\"\\nTraining finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "## 8. Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "print(f\"Loading best model from {save_path}\")\n",
    "best_model = Generic_UNetPlusPlus(\n",
    "    input_channels=input_channels,\n",
    "    base_num_features=base_num_features,\n",
    "    num_classes=num_classes,\n",
    "    num_pool=num_pool,\n",
    "    num_conv_per_stage=2,\n",
    "    feat_map_mul_on_downscale=2,\n",
    "    conv_op=nn.Conv2d,\n",
    "    norm_op=nn.BatchNorm2d,\n",
    "    norm_op_kwargs={'eps': 1e-5, 'affine': True},\n",
    "    dropout_op=nn.Dropout2d,\n",
    "    dropout_op_kwargs={'p': 0, 'inplace': True},\n",
    "    nonlin=nn.LeakyReLU,\n",
    "    nonlin_kwargs={'negative_slope': 1e-2, 'inplace': True},\n",
    "    deep_supervision=use_deep_supervision,\n",
    "    dropout_in_localization=False,\n",
    "    final_nonlin=softmax_helper,\n",
    "    weightInitializer=InitWeights_He(1e-2),\n",
    "    pool_op_kernel_sizes=pool_op_kernel_sizes,\n",
    "    conv_kernel_sizes=conv_kernel_sizes,\n",
    "    upscale_logits=False,\n",
    "    convolutional_pooling=True,\n",
    "    convolutional_upsampling=True,\n",
    "    max_num_features=None\n",
    ")\n",
    "\n",
    "try:\n",
    "    best_model.load_state_dict(torch.load(save_path, map_location=device))\n",
    "    best_model.to(device)\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "    test_loss, test_iou, test_dice = evaluate(best_model, test_loader, criterion, device, dtype, use_deep_supervision)\n",
    "    print(\"\\n--- Test Set Evaluation ---\")\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    print(f'Test IoU:  {test_iou:.4f}')\n",
    "    print(f'Test Dice: {test_dice:.4f}')\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Saved model file not found at {save_path}. Cannot evaluate.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during model loading or evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "## 9. Visualize Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def visualize_segmentation_overlay(model, dataloader, num_samples=4, device=torch.device('cuda'), dtype=torch.float32, use_deep_supervision=True):\n",
    "    \"\"\"Create and visualize an overlay of segmentation masks on original images.\"\"\"\n",
    "    model.eval()\n",
    "    if num_samples == 0:\n",
    "        return\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = np.expand_dims(axes, axis=0) # Ensure axes is always 2D\n",
    "\n",
    "    dataset = dataloader.dataset\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(indices):\n",
    "            image, mask = dataset[idx] # Get raw sample\n",
    "            image_tensor = image.unsqueeze(0).to(device, dtype=dtype)\n",
    "            mask_tensor = mask.to(device) # Ground truth mask\n",
    "\n",
    "            outputs = model(image_tensor)\n",
    "            if use_deep_supervision and isinstance(outputs, tuple):\n",
    "                final_output = outputs[0]\n",
    "            else:\n",
    "                final_output = outputs\n",
    "\n",
    "            pred_prob = torch.softmax(final_output, dim=1)\n",
    "            pred_mask = torch.argmax(pred_prob, dim=1).squeeze(0).cpu().numpy() # (H, W)\n",
    "\n",
    "            image_np = image[0].cpu().numpy()\n",
    "            mask_np = mask.squeeze(0).cpu().numpy()\n",
    "\n",
    "            # Original Image (FLAIR)\n",
    "            axes[i, 0].imshow(image_np, cmap='gray')\n",
    "            axes[i, 0].set_title(f\"Sample {idx} - Original (FLAIR)\")\n",
    "            axes[i, 0].axis('off')\n",
    "\n",
    "            # Ground Truth Overlay\n",
    "            gt_overlay = np.stack([image_np] * 3, axis=-1) # Grayscale background\n",
    "            colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "            for c in range(1, 4): # Classes 1, 2, 3\n",
    "                gt_overlay[mask_np == c] = 0.5 * gt_overlay[mask_np == c] + 0.5 * colors[c][:3]\n",
    "            axes[i, 1].imshow(np.clip(gt_overlay, 0, 1))\n",
    "            axes[i, 1].set_title(f\"Ground Truth Overlay\")\n",
    "            axes[i, 1].axis('off')\n",
    "\n",
    "            # Predicted Overlay\n",
    "            pred_overlay = np.stack([image_np] * 3, axis=-1)\n",
    "            for c in range(1, 4):\n",
    "                pred_overlay[pred_mask == c] = 0.5 * pred_overlay[pred_mask == c] + 0.5 * colors[c][:3]\n",
    "            axes[i, 2].imshow(np.clip(pred_overlay, 0, 1))\n",
    "            axes[i, 2].set_title(f\"Predicted Overlay\")\n",
    "            axes[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "print(\"Visualizing results on test set...\")\n",
    "vis_loader = DataLoader(test_dataset, batch_size=1, shuffle=False) # Use batch_size=1 for visualization\n",
    "try:\n",
    "    visualize_segmentation_overlay(best_model, vis_loader, num_samples=4, device=device, dtype=dtype, use_deep_supervision=use_deep_supervision)\n",
    "except NameError:\n",
    "    print(\"Could not visualize: 'best_model' not defined. Was training successful and the model loaded?\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during visualization: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
